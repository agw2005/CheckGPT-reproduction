{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf5f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99cc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288cc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"artifact_checkgpt/CheckGPT/exp/\"\n",
    "pattern = re.compile(\n",
    "    r\"(?P<domain>[A-Za-z0-9]+)_\"                         \n",
    "    r\"(?P<arch>[A-Za-z0-9]+)_Train_Task(?P<task>\\d+)\"\n",
    "    r\"_Prompt(?P<prompt>\\d+)_Test_Task(?P<test_task>\\d+)\"\n",
    "    r\"_Prompt(?P<test_prompt>\\d+)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d088053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for dirpath, dirnames, _ in os.walk(ROOT):\n",
    "    for d in dirnames:\n",
    "        if \"Test\" not in d:\n",
    "            continue\n",
    "\n",
    "        m = pattern.match(d)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        info = m.groupdict()\n",
    "        domain = info[\"domain\"]\n",
    "        arch = info[\"arch\"]\n",
    "        task = int(info[\"task\"])\n",
    "        prompt = int(info[\"prompt\"])\n",
    "\n",
    "        log_path = os.path.join(dirpath, d, \"train.log\")\n",
    "        if not os.path.isfile(log_path):\n",
    "            continue\n",
    "\n",
    "        test_acc = None\n",
    "        acc_gpt = None\n",
    "        acc_human = None\n",
    "        f1 = None\n",
    "\n",
    "        with open(log_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                mm = re.search(\n",
    "                    r\"Test accuracy:\\s*([\\d\\.]+)%.*?Acc_GPT:\\s*([\\d\\.]+)%.*?Acc_Human:\\s*([\\d\\.]+)%.*?F1:\\s*([\\d\\.]+)\",\n",
    "                    line\n",
    "                )\n",
    "                if mm:\n",
    "                    test_acc = float(mm.group(1))\n",
    "                    acc_gpt = float(mm.group(2))\n",
    "                    acc_human = float(mm.group(3))\n",
    "                    f1 = float(mm.group(4))\n",
    "                    break\n",
    "\n",
    "        if test_acc is None:\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"domain\": domain,\n",
    "            \"architecture\": arch,\n",
    "            \"task\": task,\n",
    "            \"prompt\": prompt,\n",
    "            \"test_accuracy\": test_acc,\n",
    "            \"acc_gpt\": acc_gpt,\n",
    "            \"acc_human\": acc_human,\n",
    "            \"f1\": f1,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df = df.sort_values(by=[\"domain\", \"architecture\", \"task\", \"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d9452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    domain       architecture  task  prompt  test_accuracy  acc_gpt  \\\n",
      "186     CS  BiLSTMwoAttention     1       1          99.90     99.9   \n",
      "106     CS  BiLSTMwoAttention     1       2          99.85     99.7   \n",
      "28      CS  BiLSTMwoAttention     1       3          99.85     99.8   \n",
      "182     CS  BiLSTMwoAttention     1       4          99.95     99.9   \n",
      "210     CS  BiLSTMwoAttention     2       1          99.40     99.2   \n",
      "..     ...                ...   ...     ...            ...      ...   \n",
      "67     PHX                RCH     2       4          98.80     98.3   \n",
      "35     PHX                RCH     3       1          95.30     97.4   \n",
      "58     PHX                RCH     3       2          94.80     95.4   \n",
      "175    PHX                RCH     3       3          95.20     96.4   \n",
      "88     PHX                RCH     3       4          96.50     96.8   \n",
      "\n",
      "     acc_human      f1  \n",
      "186       99.9  0.9990  \n",
      "106      100.0  0.9985  \n",
      "28        99.9  0.9985  \n",
      "182      100.0  0.9995  \n",
      "210       99.6  0.9940  \n",
      "..         ...     ...  \n",
      "67        99.3  0.9879  \n",
      "35        93.2  0.9540  \n",
      "58        94.2  0.9483  \n",
      "175       94.0  0.9526  \n",
      "88        96.2  0.9651  \n",
      "\n",
      "[229 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.to_csv(\"results_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
