{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad9e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b5f4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_DIR = \"/home/cc/CheckGPT-reproduction/artifact_checkgpt/CheckGPT/exp\"\n",
    "METRIC_PATTERN = re.compile(\n",
    "    r\"Test accuracy:\\s*([\\d.]+)%.*, \"\n",
    "    r\"Acc_GPT:\\s*([\\d.]+)%.*, \"\n",
    "    r\"Acc_Human:\\s*([\\d.]+)%.*, \"\n",
    "    r\"F1:\\s*([\\d.]+)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c14dcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(folder_name):\n",
    "    if \"CheckGPTArch\" in folder_name:\n",
    "        return \"CheckGPTArch\"\n",
    "    if \"RCH\" in folder_name:\n",
    "        return \"RCH\"\n",
    "    if \"MLP\" in folder_name:\n",
    "        return \"MLP\"\n",
    "    if \"CNN\" in folder_name:\n",
    "        return \"CNN\"\n",
    "    if \"BiLSTMwoAttention\" in folder_name:\n",
    "        return \"BiLSTMwoAttention\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25580b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for folder in os.listdir(EXP_DIR):\n",
    "    if \"_Test_\" not in folder:\n",
    "        continue\n",
    "\n",
    "    folder_path = os.path.join(EXP_DIR, folder)\n",
    "    log_path = os.path.join(folder_path, \"train.log\")\n",
    "\n",
    "    if not os.path.isfile(log_path):\n",
    "        continue\n",
    "\n",
    "    parts = folder.split(\"_\")\n",
    "    domain = parts[0]  # CS / PHX / HSS\n",
    "    task = int(parts[-2].replace(\"Task\", \"\"))\n",
    "    prompt = int(parts[-1].replace(\"Prompt\", \"\"))\n",
    "    classification = get_classification(folder)\n",
    "\n",
    "    with open(log_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            match = METRIC_PATTERN.search(line)\n",
    "            if match:\n",
    "                test_acc, acc_gpt, acc_human, f1 = match.groups()\n",
    "                records.append({\n",
    "                    \"domain\": domain,\n",
    "                    \"task\": task,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"classification\": classification,\n",
    "                    \"test_accuracy\": float(test_acc),\n",
    "                    \"acc_gpt\": float(acc_gpt),\n",
    "                    \"acc_human\": float(acc_human),\n",
    "                    \"f1\": float(f1),\n",
    "                    \"expid\": folder\n",
    "                })\n",
    "                break\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sort_values(\n",
    "    by=[\"domain\", \"classification\", \"task\", \"prompt\"]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f02d9d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    domain  task  prompt     classification  test_accuracy  acc_gpt  \\\n",
      "0       CS     1       1  BiLSTMwoAttention          99.90     99.9   \n",
      "1       CS     1       2  BiLSTMwoAttention          99.85     99.7   \n",
      "2       CS     1       3  BiLSTMwoAttention          99.85     99.8   \n",
      "3       CS     1       4  BiLSTMwoAttention          99.95     99.9   \n",
      "4       CS     2       1  BiLSTMwoAttention          99.40     99.2   \n",
      "..     ...   ...     ...                ...            ...      ...   \n",
      "175    PHX     2       4                RCH          98.80     98.3   \n",
      "176    PHX     3       1                RCH          95.30     97.4   \n",
      "177    PHX     3       2                RCH          94.80     95.4   \n",
      "178    PHX     3       3                RCH          95.20     96.4   \n",
      "179    PHX     3       4                RCH          96.50     96.8   \n",
      "\n",
      "     acc_human      f1                                    expid  \n",
      "0         99.9  0.9990  CS_Test_BiLSTMwoAttention_Task1_Prompt1  \n",
      "1        100.0  0.9985  CS_Test_BiLSTMwoAttention_Task1_Prompt2  \n",
      "2         99.9  0.9985  CS_Test_BiLSTMwoAttention_Task1_Prompt3  \n",
      "3        100.0  0.9995  CS_Test_BiLSTMwoAttention_Task1_Prompt4  \n",
      "4         99.6  0.9940  CS_Test_BiLSTMwoAttention_Task2_Prompt1  \n",
      "..         ...     ...                                      ...  \n",
      "175       99.3  0.9879               PHX_Test_RCH_Task2_Prompt4  \n",
      "176       93.2  0.9540               PHX_Test_RCH_Task3_Prompt1  \n",
      "177       94.2  0.9483               PHX_Test_RCH_Task3_Prompt2  \n",
      "178       94.0  0.9526               PHX_Test_RCH_Task3_Prompt3  \n",
      "179       96.2  0.9651               PHX_Test_RCH_Task3_Prompt4  \n",
      "\n",
      "[180 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4001379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"repro_checkpoint_2_validation_result.xlsx\"\n",
    "df.to_excel(\n",
    "    output_path,\n",
    "    index=False,\n",
    "    engine=\"openpyxl\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
